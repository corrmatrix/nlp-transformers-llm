## Purpose
Assemble a valuable collection of latest information and learning resources on NLP, Transformers and Large Language Model.

## Last News

- Stability Diffusion - SD-XL 1.0-base Model Card: https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0 - 28/07/2023

- Stack overflow search - OverflowAI : https://twitter.com/StackOverflow/status/1684530704850243584 - 27/07/2023

- Meta's Open Source Llama Upsets the AI Horse Race: https://www.wired.com/story/metas-open-source-llama-upsets-the-ai-horse-race - 26/07/2023

- Bringing General AI to search experience : https://cloud.google.com/blog/products/ai-machine-learning/enterprise-search-on-gen-app-builder - 21/07/2023

- Meta and Microsoft Introduce the Next Generation of Llama : https://about.fb.com/news/2023/07/llama-2 - 18/07/2023

- Anthropic's 'friendly' AI chatbot, Claude, is now available for more people to try : https://www.theverge.com/2023/7/11/23790254/anthropic-claude-chatbot-ai-available-beta - Only available for USA and UK - 11/07/2023

- Bard's latest update: more features, languages and countries : https://blog.google/products/bard/google-bard-new-features-update-july-2023 - 13/07/2023

- GPT-4 Architecture, datasets and costs leaked : https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked - Mixture of Experts (MoE) - 11/07/2023

- GPT-4's Secret Has Been Revealed : https://thealgorithmicbridge.substack.com/p/gpt-4s-secret-has-been-revealed -> https://twitter.com/swyx/status/1671272883379908608 (George Hotz) - GPT-4 - Mixture of smaller models - 24/06/2023

- Claude vs ChatGPT for Data Science: A Comparative Analysis : https://www.datacamp.com/blog/claude-vs-chatgpt-data-science-comparison  - 30/06/2023

- Databricks Strikes $1.3 Billion Deal for Generative AI Startup MosaicML : https://www.wsj.com/articles/databricks-strikes-1-3-billion-deal-for-generative-ai-startup-mosaicml-fdcefc06 - 30/06/2023

- AI is killing the old web, and the new web struggles to be born : https://www.theverge.com/2023/6/26/23773914/ai-large-language-models-data-scraping-generation-remaking-web - 27/06/2023

- AI Package Hallucinations : https://vulcan.io/blog/ai-hallucinations-package-risk - 06/06/2023

- GPT-4 has more than a trillion parameters: https://the-decoder.com/gpt-4-has-a-trillion-parameters -  25/03/2023

- Meta's powerful AI language model has leaked online â€” what happens now?: https://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse - 09/03/2023

## Articles and research papers

- GPTQ: ACCURATE POST-TRAINING QUANTIZATION
FOR GENERATIVE PRE-TRAINED TRANSFORMERS : https://arxiv.org/pdf/2210.17323.pdf - 22/03/2023

- Understanding Large Language Models : A Transformative Reading List :  https://sebastianraschka.com/blog/2023/llm-reading-list.html - **Sebastian Raschka** - Feb 7, 2023

- Openai Research : https://openai.com/research

- (GPT1) Improving Language Understanding
by Generative Pre-Training : https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf - see also https://openai.com/research/language-unsupervised and https://huggingface.co/docs/transformers/model_doc/openai-gpt - **Radford et. al.** - 2018

- (GPT-2) Language Models are Unsupervised Multitask Learners (2019): https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf - see also https://openai.com/research/better-language-models and https://github.com/openai/gpt-2 (source code) - **Radford et. al.** - 2019

- (GPT-3) Language models are few-shot learners : https://openai.com/research/language-models-are-few-shot-learners and https://arxiv.org/abs/2005.14165 - **Brown et. al.** - May 28, 2020

- Attention Is All You Need: https://arxiv.org/abs/1706.03762 and https://arxiv.org/pdf/1706.03762.pdf - 12 Jun 2017

## Resources

### Github and softwares

- bitsandbytes : https://github.com/TimDettmers/bitsandbytes - a lightweight wrapper around CUDA custom functions, in particular 8-bit optimizers, matrix multiplication (LLM.int8()), and quantization functions

- Dalai : https://github.com/cocktailpeanut/dalai - Run LLaMA and Alpaca on your computer

- GGML : https://github.com/ggerganov/ggml

- koboldcpp : https://github.com/LostRuins/koboldcpp/wiki

- LoRA: Low-Rank Adaptation of Large Language Models : https://github.com/microsoft/LoRA

- Llama : https://github.com/facebookresearch/llama

- llama.cpp : https://github.com/ggerganov/llama.cpp

- LMSYS - Fastchat: https://github.com/lm-sys/FastChat -> Vicuna : https://lmsys.org/blog/2023-03-30-vicuna - Cost of training Vicuna-13B is around $300 -> Vicuna Installation Guide : https://github.com/vicuna-tools/vicuna-installation-guide

- Parameter-Efficient Fine-Tuning (PEFT) methods : https://github.com/huggingface/peft - enable efficient adaptation of pre-trained language models (PLMs) to various downstream applications without fine-tuning all the model's parameters

- QLoRA: Efficient Finetuning of Quantized LLMs : https://github.com/artidoro/qlora

- RedPajama-Data : https://github.com/togethercomputer/RedPajama-Data - An Open Source Recipe to Reproduce LLaMA training dataset

- Stable Diffusion web UI : https://github.com/AUTOMATIC1111/stable-diffusion-webui

- Web LLM : https://github.com/mlc-ai/web-llm

- WizardVicunaLM : https://github.com/melodysdreamj/WizardVicunaLM - Wizard's dataset + ChatGPT's conversation extension + Vicuna's tuning method

- OpenAI : https://openai.com

- Midjourney : https://www.midjourney.com

- Stable diffusion : https://stability.ai/stablediffusion




### Learning/Education

- Practical Deep Learning : https://course.fast.ai/Lessons/lesson1.html

- Introduction to Large Lange Models : https://docs.cohere.com/docs/introduction-to-large-language-models


- LLM Bootcamp - Spring 2023 : https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/

- Machine learning mastery : https://machinelearningmastery.com/start-here/

- The transformer model, explained clearly : https://www.deriveit.org/notes/119


- Attention is all you need; Attentional Neural Network Models : https://www.youtube.com/watch?v=rBCqOTEfxvg - **Lukasz Kaiser** - Oct 2017

- How GPT3 Works - Easily Explained with Animations : https://www.youtube.com/watch?v=MQnJZuBGmSQ - **Jay Alammar** - Aug 2020 - Basic overview

- The Narrated Transformer Language Model : https://www.youtube.com/watch?v=-QH8fRhqFHM - **Jay Alammar** - Aug 2020 - Details on architecture


### Discord and related github
- Dalai: https://discord.gg/WWfgrzzkCT and https://github.com/cocktailpeanut/dalai - Run LLaMA and Alpaca on your computer

- FastChat (LMSys) : https://discord.gg/HSWAKCrnFx and https://github.com/lm-sys/FastChat and https://chat.lmsys.org - FastChat is an open platform for training, serving, and evaluating large language model based chatbots

- Text generation web UI: https://discord.gg/jwZCF2dPQN and https://github.com/oobabooga/text-generation-webui

- Tom Jobbins (TheBloke) : https://discord.gg/theblokeai and https://github.com/TheBloke

